---
title: "Dokumentation der Datenaufbereitung:"
title-secondline: "'Dataset 71.txt'"
subtitle: "Empririsch Wissenschaftliches Arbeiten"
shorttitle: "Datenaufbereitung: 'Dataset 71.txt'"

author: 
  - name          : "Prof. Dr. Stephan Huber"
    affiliation   : "1,2"
    corresponding : true
    address       : "Im Mediapark 4e"
    email         : "stephan.huber@hs-fresenius.de"

university: "Charlotte Fresenius Hochschule"
studiengang: "Studiengang: Psychologie (B. Sc.)"
place: "Studienort: Köln"

gutachter: "---"
date: today
date-format: "DD.MM.YYYY"


semester-eins: ""
author-zwei: ""
semester-zwei: ""
author-drei: ""
semester-drei: ""
bibliography: literatur.bib
# csl: "https://www.zotero.org/styles/deutsche-gesellschaft-fur-psychologie"
format:
  apaquarto-pdf:
    documentmode: stu
toc: true
floatsintext: false
number-sections: false
a4paper: true
fontsize: 12pt
lang: de
---

# Zusammenfassung {.unnumbered}

\noindent Dieses Dokument beschreibt die Datenaufbereitung der Datei 'Dataset 71.txt' und stellt sicher, dass die Ergebnisse replizierbar sind. Alle Schritte werden mit R durchgeführt.

\newpage
# Datenbeschreibung

Über den Datensatz ist nur wenig bekannt. Es gibt 21 Variablen, die Items einer Umfrage darstellen. Die Antwortmöglichkeiten sind auf einer fünfstufigen Likert-Skala angegeben.

# Datenaufbereitung

## Vorbereitung

Zunächst werden die benötigten R-Pakete geladen. Hierzu verwende ich das Paket `pacman`. Sollte dieses Paket auf dem verwendeten Computer nicht installiert sein, wird es mit der ersten der folgenden Zeilen installiert. Die zweite Zeile lädt die benötigten Pakete und die dritte bereinigt den aktuellen Arbeitsbereich. 

```{r, echo=TRUE, message=FALSE}
if (!require(pacman)) install.packages("pacman")
pacman::p_load(tidyverse, janitor, psych, tinytable, ggstats,
               modelsummary, knitr, kableExtra, labelled)
rm(list = ls())
```  

## Datenimport

Die Datei "Dataset 71.txt" wird mit der Funktion `read.delim` in R eingelesen. 

```{r, echo=TRUE, message=FALSE, output = FALSE, warning=FALSE}
df_raw <- read.delim("Dataset 71.txt")
```

@tbl-df_raw_glim zeigt einen Ausschnitt des Rohdatensatzes.^[Dieses Objekt wird mit der Funktion `tt` aus dem Paket `tinytable` veranschaulicht [@tinytable2024].]


```{r , echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-df_raw_glim
#| echo: false
#| tbl-cap: "Ausschnitt des Rohdatensatz"

head_df_raw <- head(df_raw)
tt(head_df_raw[,1:11])

```

## Datenexploration

Im Folgenden werde ich die Daten genauer untersuchen, um eventuelle Datenfehler zu identifizieren und diese später zu bereinigen. Zunächst ist festzuhalten, dass folgende Werte im Datensatz vorhanden sind: `r unique(unlist(df_raw))`. Ohne die Variable `ID`, die offensichtlich eine laufende Nummer von 1 bis 70 ist, sind folgende Werte enthalten: `r df_raw |> select(-ID) |> as.matrix() |> as.vector() |> unique()`. Das ist seltsam. Eigentlich sollten hier, entsprechend der Likert-Skala, nur Werte von 1 bis 5 enthalten sein. Die folgenden Tabellen sollen einen besseren Einblick in den Datensatz ermöglichen: 

- @tbl-df_raw_unique zeigt für jede im Datensatz enthaltene Variable die unterschiedlichen Werte an.^[Die Datengrundlage wird manuell erstellt. Hierbei kommen verschiedene Funktionen des `dplyr` Pakets zum Einsatz [@dplyr2023]. Dargestellt wird der Datensatz mit  der Funktion `kable` aus dem `knitr` Paket [@knitr2024.]]
- @tbl-df_long zeigt, in wie vielen verschiedenen Items bestimmte Beobachtungen vorkommen.^[@tbl-df_long wird mit Hilfe der Funktion `tabyl` erstellt, die Teil des Pakets `janitor` ist [@janitor2023].] 
- @tbl-df_raw_skim zeigt einige deskriptive Statistiken. Hier fällt auf, dass `NaN` enthalten sind und einige ungewöhnliche Werte, die außerhalb der Skala von 1 bis 5 liegen.^[@tbl-df_raw_skim wird mit Hilfe der Funktion `datasummary_skim` erstellt, die Teil des Pakets `modelsummary` ist [@modelsummary2022].]  


Diese Anomalien müssen später bereinigt beziehungsweise vermerkt werden.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-df_raw_unique
#| echo: false
#| tbl-cap: "Unterschiedliche Werte in den Variablen"
#| fig-align: left


uv <- df_raw |> 
  select(-ID) |> 
  as.matrix() |> 
  as.vector() |> 
  unique()

uv_item <- df_raw |> 
  select(-ID) |> 
  map(~ list(Values = unique(.) |> sort())) |> 
  enframe(name = "Attribute", value = "Values") |>  
  tibble()
  

# Create and display the table using kable
uv_item |> 
   kable("latex", booktabs = TRUE, longtable = TRUE) 
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: tbl-df_long
#| echo: false
#| tbl-cap: "Häufigkeitstabelle der unterschiedlichen Werte (pro item)"
#| apa-note: "Die Tabelle zeigt an, in wie vielen Items die jeweiligen Werte vorkommen."

long <- df_raw  |> 
  pivot_longer(!ID, names_to = "item", values_to = "count") |> 
  distinct(item, count) |> 
  arrange(item, count) 

long$count |> 
  tabyl() |> 
  kable("latex", booktabs = TRUE) 

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: tbl-df_raw_skim
#| echo: false
#| tbl-cap: "Deskriptive Statistiken zum Rohdatensatz"

datasummary_skim(df_raw, output = "latex")
```

## Datenbereinigung

Zunächst nehme ich einige kosmetische Bereinigungen vor. Dabei passe ich die Variablennamen entsprechend gängigen Konventionen an, indem ich Leerzeichen und Punkte entferne sowie Großbuchstaben vermeide. Dies geschieht mit der Funktion `clean_names`. Darüber hinaus werden die NaN-Werte durch NA ersetzt, und die Beobachtungen gelöscht, die in allen Items ausschließlich fehlende Werte enthalten.


```{r, echo=TRUE, message=FALSE}
df_cosmetic <- df_raw |>
  clean_names() |>
  as_tibble() |>
  # Ersetzen von NaN-Werten durch NA
  mutate(across(everything(), ~ if_else(is.nan(.), NA, .))) |>
  #Entfernen von Zeilen, bei denen alle "item_"-Spalten NA sind
  rowwise() |> 
  filter(!all(across(starts_with("item_"), ~ is.na(.)))) |> 
  ungroup()
```  

Wie bereits erwähnt, gibt es einige fehlende Werte (`NA`) sowie ungewöhnliche Werte, die außerhalb der Likert-Skala liegen, also nicht im Wertebereich von 1 bis 5. Diese gilt es zu identifizieren. Da ich die genauen Gründe hierfür nicht kenne, werde ich dazu verschiedene Variablen erzeugen. Die genaueren Beschreibungen zu den Variablen befinden sich als Kommentar im folgenden Code-Ausschnitt:

```{r, echo=TRUE, message=FALSE}
df <- df_cosmetic |>
  rowwise() |>
  # Berechnung des größten absoluten Werts in "item_"-Spalten für jede Zeile
  mutate(outlier = max(abs(c_across(starts_with("item_"))), na.rm = TRUE)) |>
  # Markieren, ob ein Ausreißer (> 5 oder gleich 0) vorhanden ist
  mutate(has_outlier = if_else(outlier > 5 | outlier == 0, TRUE, FALSE)) |>
  # Zählen der Werte, die größer als 5 sind, für jede Zeile
  mutate(count_larger_5 = 
           sum( c_across(starts_with("item_")) > 5 | 
                c_across(starts_with("item_")) == 0, na.rm = TRUE)) |> 
  # Zählen der Tippfehler (11, 22, 33, 44, 55) für jede Zeile
  mutate(count_typos = sum(c_across(starts_with("item_")) %in% 
                             c(11, 22, 33, 44, 55), na.rm = TRUE)) |> 
  # Markieren, ob mehr Werte größer als 5 sind als Tippfehler
  mutate(has_larger_5_notypos = (count_typos < count_larger_5)) |> 
  # Markieren, ob Tippfehler vorhanden sind
  mutate(has_typos = count_typos > 0 ) |>
  # Markieren, ob NA-Werte in "item_"-Spalten vorhanden sind
  mutate(has_nas = if_else(anyNA(pick(starts_with("item_"))), TRUE, FALSE)) |>
  # Markieren, ob eine Zeile vollständig ist (keine Ausreißer und keine NAs)
  mutate(complete = (has_outlier == FALSE & has_nas == FALSE)) |> 
  ungroup()
```  

Die Variablen `has_typos`, `has_nas`, `has_larger_5_notypos` und `has_outlier` zeigen nun an, ob und welche Probleme in der jeweiligen Beobachtung vorliegen. Diese Variablen sind wie folgt definiert:

- `has_nas`: Ist `TRUE`, wenn mindestens eine Beobachtung ein `NA` ist.
- `has_typos`: Ist `TRUE`, wenn mindestens eine Beobachtung die Werte 11, 22, 33, 44 oder 55 aufweist.
- `has_outlier`: Ist `TRUE`, wenn mindestens eine Beobachtung einen Wert größer als 5 (in absoluten Zahlen) aufweist.
- `has_larger_5_notypos`: Ist `TRUE`, wenn mindestens eine Beobachtung einen Wert größer als 5 (in absoluten Zahlen) aufweist und diese Zahl(en) nicht 11, 22, 33, 44 oder 55 ist.

Die Werte 11, 22, 33, 44 oder 55 könnten Tippfehler sein, bei denen die Zahl versehentlich doppelt eingegeben wurde. Dies werde ich später versuchen zu berücksichtigen und zu bereinigen.

## Datensatzerstellung

In diesem Schritt erstelle ich Datensätze, die ich zur Analyse verwenden kann. Hierbei werde ich zwei verschiedene Datensätze erstellen. Einen Datensatz, in dem ich ausschließlich Beobachtungen berücksichtige, die scheinbar frei von Fehleingaben und fehlenden Werten sind. Dieser Datensatz wird als `df_complete` bezeichnet. Darüber hinaus speichere ich alle Variablen, entsprechend der Likert-Skala, als Faktorvariablen ab und versehe sie mit einem entsprechenden Label.


Die Variablen `has_typos`, `has_nas`, `has_larger_5_notypos` und `has_outlier` indizieren nun, ob und welche Probleme in der jeweiligen Beobachtung vorliegen. Die Variablen sind wie folgt definiert:

- `has_nas`: Ist `TRUE`, wenn mindestens eine Beobachtung ein `NA` ist. 
- `has_typos`: Ist `TRUE`, wenn mindestens eine Beobachtung die Werte 11, 22, 33, 44, oder 55 aufweist.
- `has_outlier`: Ist `TRUE`, wenn mindestens eine Beobachtung die Werte in absoluten Zahlen größer als 5 ist
- `has_larger_5_notypos`: Ist `TRUE`, wenn mindestens eine Beobachtung die Werte in absoluten Zahlen größer als 5 ist und diese Zahl(en) nicht 11, 22, 33, 44, oder 55 ist. 

Die Werte 11, 22, 33, 44, oder 55 könnten besonders sein, denn hier könnte man vermuten, dass hier schlicht ein Tippfehler vorliegt. Also die Zahl versehentlich doppelt eingegeben wurde. Dies werde ich später versuchen, zu berücksichtigen und zu bereinigen.


```{r, echo=TRUE, message=FALSE}
# Labels definieren
likert_levels <- c(
  "Stimme überhaupt nicht zu",
  "Stimme nicht zu",
  "Neutral",
  "Stimme zu",
  "Stimme voll und ganz zu"
)

# Faktorisierung der Items und hinzufügen eines Labels
df_chr <- df |> 
  mutate(across(starts_with("item_"), 
                ~ case_when(
                  . == 1 ~ "Stimme überhaupt nicht zu",
                  . == 2 ~ "Stimme nicht zu",
                  . == 3 ~ "Neutral",
                  . == 4 ~ "Stimme zu",
                  . == 5 ~ "Stimme voll und ganz zu",
                  TRUE ~ as.character(.)
                ))) |> 
  mutate(across(starts_with("item_"), ~ factor(.x, levels = likert_levels)))

df_complete <- df_chr |> 
  filter(complete == TRUE) 
  
```  

Der Datensatz `df_complete` hat `r nrow(df_complete)` Beobachtungen.

Der zweite Datensatz ist als `df_cleaned` betitelt. Hierbei unterstelle ich, dass es sich bei den Eingaben mit den Werten 11, 22, 33, 44 oder 55 um Tippfehler handelt. Diese rekodiere ich entsprechend in 1, 2, 3, 4 und 5 um. Alle übrigen Werte außerhalb des Wertebereichs 1 bis 5 bezeichne ich als `NA`.




```{r, echo=TRUE, message=FALSE}
df_cleaned <- df |> 
  # Ersetzen von bestimmten Werten (11, 22, 33, 44, 55) in "item_"-Spalten
  mutate(across(starts_with("item_"), ~ case_when(
    . == 11 ~ 1,
    . == 22 ~ 2,
    . == 33 ~ 3,
    . == 44 ~ 4,
    . == 55 ~ 5,
    TRUE ~ .
  ))) |> 
  # Ersetzen von Werten größer als 5 durch NA in "item_"-Spalten
  mutate(across(starts_with("item_"), ~ if_else(. > 5 | . == 0, NA, .))) |> 
  mutate(across(starts_with("item_"), 
                ~ case_when(
                  . == 1 ~ "Stimme überhaupt nicht zu",
                  . == 2 ~ "Stimme nicht zu",
                  . == 3 ~ "Neutral",
                  . == 4 ~ "Stimme zu",
                  . == 5 ~ "Stimme voll und ganz zu",
                  TRUE ~ as.character(.)
                ))) |> 
  mutate(across(starts_with("item_"), ~ factor(.x, levels = likert_levels)))

```  
Der Datensatz `df_cleaned` hat `r nrow(df_cleaned)` Beobachtungen.

Schließlich speichere ich die aktuelle Arbeitsumgebung in einer `.RData`-Datei.


```{r, echo=TRUE, message=FALSE}
save.image("data_71.RData")
```
# Auswertung

## Antwortverteilung zu den gestellten Fragen 

@fig-df_com_gglik und @fig-df_cle_gglik zeigen die Verteilung der Antworten. Die erste Abbildung verwendet den Datensatz `df_complete`, bei dem nur die Befragungen berücksichtigt wurden, bei denen keine Auffälligkeiten gefunden wurden. Die zweite Abbildung verwendet den Datensatz `df_cleaned`, bei dem einige Bereinigungen durchgeführt wurden und einige Fragen nicht verfügbar waren.^[Beide Abbildungen werden mit der Funktion `gglikert` erstellt, welche Teil des `ggstats`-Pakets ist [@ggstats2024].]



```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: fig-df_com_gglik
#| echo: false
#| fig-cap: "Antwortverteilung zu den gestellten Fragen (df_complete)"

gglikert(df_complete, include = starts_with("item_"))
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: fig-df_cle_gglik
#| echo: false
#| fig-cap: "Antwortverteilung zu den gestellten Fragen (df_cleaned)"

gglikert(df_cleaned, include = starts_with("item_"))
```

## Überprüfung der neu erstellten Datensätze

@tbl-df_com_unique und @tbl-df_cle_unique enthalten die unterschiedliche Werte in den Variablen für die Datensätze `df_complete` und `df_cleaned`. 


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-df_com_unique
#| echo: false
#| tbl-cap: "Unterschiedliche Werte in den Variablen (df_complete)"

uv_item <- df_complete |> 
  select(-id) |> 
  select(group, starts_with("item_")) |>  
  map(~ list(Values = unique(.) |> sort())) |> 
  enframe(name = "Attribute", value = "Values") |>  
  tibble()
  

# Create and display the table using kable
uv_item |> 
   kable("latex", booktabs = TRUE, longtable = TRUE) 
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-df_cle_unique
#| echo: false
#| tbl-cap: "Unterschiedliche Werte in den Variablen (df_cleaned)"

uv_item <- df_cleaned |> 
  select(-id) |> 
  select(group, starts_with("item_")) |>  
  map(~ list(Values = unique(.) |> sort())) |> 
  enframe(name = "Attribute", value = "Values") |>  
  tibble()
  

# Create and display the table using kable
uv_item |> 
   kable("latex", booktabs = TRUE, longtable = TRUE) 
```




<!-- # ```{r include=FALSE} -->
<!-- # knitr::purl("doc_read_in_71.qmd") -->
<!-- # ``` -->




\newpage
# Literaturverzeichnis {.unnumbered}

::: {#refs}
:::
